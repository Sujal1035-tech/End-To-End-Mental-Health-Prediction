{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202ab05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8dbd2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\end to end mental_health_prediction\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d1d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7520080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\end to end mental_health_prediction'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62806c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220650be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    drop_columns: List[str]\n",
    "    columns_to_fillna: Dict[str, str]\n",
    "    columns_to_drop_due_to_missing: List[str]\n",
    "    top_features: int\n",
    "    scaler_path: Path\n",
    "    processed_train_data_path: Path\n",
    "    processed_test_data_path: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0799951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml,create_directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0556cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH,\n",
    "        schema_filepath=SCHEMA_FILE_PATH\n",
    "    ):\n",
    "        # Force convert to Path object in case they are strings\n",
    "        config_filepath = Path(config_filepath)\n",
    "        params_filepath = Path(params_filepath)\n",
    "        schema_filepath = Path(schema_filepath)\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self):\n",
    "        config = self.config.data_transformation\n",
    "        schema = self.schema\n",
    "\n",
    "        return DataTransformationConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            data_path=Path(config.data_path),\n",
    "            drop_columns=schema.get(\"drop_columns\", []),\n",
    "            columns_to_fillna=schema.get(\"columns_to_fillna\", {}),\n",
    "            columns_to_drop_due_to_missing=schema.get(\"columns_to_drop_due_to_missing\", []),\n",
    "            top_features=self.params.data_transformation.top_features,\n",
    "            scaler_path=Path(config.scaler_path),\n",
    "            processed_train_data_path=Path(config.processed_train_data_path),\n",
    "            processed_test_data_path=Path(config.processed_test_data_path)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb5a0d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def load_data(self):\n",
    "        logging.info(f\"ðŸ“„ Loading data from: {self.config.data_path}\")\n",
    "        return pd.read_csv(self.config.data_path)\n",
    "\n",
    "    def drop_columns(self, df):\n",
    "        logging.info(\"ðŸ§¹ Dropping unnecessary columns\")\n",
    "        cols_to_drop = [\"Timestamp\", \"comments\", \"state\"] if \"Timestamp\" in df.columns else []\n",
    "        return df.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    def fill_missing(self, df):\n",
    "        logging.info(\"ðŸ©¹ Filling missing values\")\n",
    "        return df.fillna(df.mode().iloc[0])\n",
    "\n",
    "    def clean_age(self, df):\n",
    "        logging.info(\"ðŸ”¢ Cleaning Age column\")\n",
    "        df = df.copy()\n",
    "        df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
    "        df = df[(df['Age'] >= 10) & (df['Age'] <= 100)]\n",
    "        return df\n",
    "\n",
    "    def normalize_gender(self, df):\n",
    "        logging.info(\"ðŸš» Normalizing Gender column\")\n",
    "        df = df.copy()\n",
    "        df['Gender'] = df['Gender'].astype(str).str.lower().str.strip()\n",
    "\n",
    "        def clean_gender(val):\n",
    "            if 'male' in val:\n",
    "                return 'male'\n",
    "            elif 'female' in val:\n",
    "                return 'female'\n",
    "            else:\n",
    "                return 'other'\n",
    "\n",
    "        df['Gender'] = df['Gender'].apply(clean_gender)\n",
    "        return df\n",
    "\n",
    "    def reduce_countries(self, df):\n",
    "        logging.info(\"ðŸŒ Reducing countries to top 4\")\n",
    "        df = df.copy()\n",
    "        top_4 = df['Country'].value_counts().nlargest(4).index.tolist()\n",
    "        df['Country'] = df['Country'].apply(lambda x: x if x in top_4 else 'Other')\n",
    "        return df\n",
    "\n",
    "    def encode_features(self, df):\n",
    "        logging.info(\"ðŸ·ï¸ Encoding categorical columns\")\n",
    "        df = df.copy()\n",
    "        le = LabelEncoder()\n",
    "\n",
    "        cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "        for col in cat_cols:\n",
    "            # Convert all to str to avoid 'str' & 'bool' mixed error\n",
    "            df[col] = df[col].astype(str)\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "        return df\n",
    "\n",
    "    def select_features(self, X, y):\n",
    "        logging.info(\"âœ¨ Selecting top features\")\n",
    "        selector = SelectKBest(score_func=f_classif, k=self.config.top_features)\n",
    "        X_new = selector.fit_transform(X, y)\n",
    "        return X_new, selector.get_support(indices=True)\n",
    "\n",
    "    def scale_features(self, X):\n",
    "        logging.info(\"ðŸ“ Scaling features\")\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        # âœ… Ensure scaler path directory exists\n",
    "        scaler_dir = os.path.dirname(self.config.scaler_path)\n",
    "        os.makedirs(scaler_dir, exist_ok=True)\n",
    "        joblib.dump(scaler, self.config.scaler_path)\n",
    "        return X_scaled\n",
    "\n",
    "    def split_and_save(self, X, y):\n",
    "        logging.info(\"âœ‚ï¸ Splitting data and saving\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        train = pd.DataFrame(X_train)\n",
    "        train['treatment'] = y_train.reset_index(drop=True)\n",
    "        test = pd.DataFrame(X_test)\n",
    "        test['treatment'] = y_test.reset_index(drop=True)\n",
    "\n",
    "        # âœ… Ensure output directories exist\n",
    "        os.makedirs(os.path.dirname(self.config.processed_train_data_path), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(self.config.processed_test_data_path), exist_ok=True)\n",
    "\n",
    "        train.to_csv(self.config.processed_train_data_path, index=False)\n",
    "        test.to_csv(self.config.processed_test_data_path, index=False)\n",
    "\n",
    "    def run(self):\n",
    "        df = self.load_data()\n",
    "        df = self.drop_columns(df)\n",
    "        df = self.fill_missing(df)\n",
    "        df = self.clean_age(df)\n",
    "        df = self.normalize_gender(df)\n",
    "        df = self.reduce_countries(df)\n",
    "        df = self.encode_features(df)\n",
    "\n",
    "        X = df.drop(columns='treatment')\n",
    "        y = df['treatment']\n",
    "\n",
    "        X_selected, selected_indices = self.select_features(X, y)\n",
    "        X_scaled = self.scale_features(X_selected)\n",
    "        self.split_and_save(X_scaled, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "957b39dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-20 21:14:36,082: INFO: common: yaml file: D:\\end to end mental_health_prediction\\config.yaml loaded successfully]\n",
      "[2025-07-20 21:14:36,082: INFO: common: yaml file: D:\\end to end mental_health_prediction\\params.yaml loaded successfully]\n",
      "[2025-07-20 21:14:36,089: INFO: common: yaml file: D:\\end to end mental_health_prediction\\schema.yaml loaded successfully]\n",
      "[2025-07-20 21:14:36,092: INFO: common: created directory at: artifacts]\n",
      "[2025-07-20 21:14:36,092: INFO: 511715814: ðŸ“„ Loading data from: artifacts\\data_ingestion\\unzipped_data\\survey.csv]\n",
      "[2025-07-20 21:14:36,103: INFO: 511715814: ðŸ§¹ Dropping unnecessary columns]\n",
      "[2025-07-20 21:14:36,104: INFO: 511715814: ðŸ©¹ Filling missing values]\n",
      "[2025-07-20 21:14:36,118: INFO: 511715814: ðŸ”¢ Cleaning Age column]\n",
      "[2025-07-20 21:14:36,118: INFO: 511715814: ðŸš» Normalizing Gender column]\n",
      "[2025-07-20 21:14:36,123: INFO: 511715814: ðŸŒ Reducing countries to top 4]\n",
      "[2025-07-20 21:14:36,126: INFO: 511715814: ðŸ·ï¸ Encoding categorical columns]\n",
      "[2025-07-20 21:14:36,143: INFO: 511715814: âœ¨ Selecting top features]\n",
      "[2025-07-20 21:14:36,145: INFO: 511715814: ðŸ“ Scaling features]\n",
      "[2025-07-20 21:14:36,152: INFO: 511715814: âœ‚ï¸ Splitting data and saving]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.run()\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38afef7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
